{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12771680,"sourceType":"datasetVersion","datasetId":8074008},{"sourceId":12818848,"sourceType":"datasetVersion","datasetId":8084016}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"71bebe39","cell_type":"markdown","source":"# ***CNN + RNN***","metadata":{"id":"71bebe39"}},{"id":"8eecd396","cell_type":"markdown","source":"## Import Required Libs","metadata":{"id":"8eecd396"}},{"id":"0312ccb2","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import Model\nfrom keras.models import Sequential\nfrom keras.layers import LayerNormalization, Embedding, Layer, Conv1D, ReLU, Concatenate, MaxPooling1D, Flatten, Dense, GlobalMaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, BatchNormalization, Activation, Dropout, LSTM, Bidirectional\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.initializers import HeNormal\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n)\nfrom keras import backend as K","metadata":{"id":"0312ccb2","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:37:25.638241Z","iopub.execute_input":"2025-08-27T13:37:25.638589Z","iopub.status.idle":"2025-08-27T13:37:25.651854Z","shell.execute_reply.started":"2025-08-27T13:37:25.638561Z","shell.execute_reply":"2025-08-27T13:37:25.646230Z"}},"outputs":[],"execution_count":26},{"id":"d9e95110-7dda-44c8-818d-f8555259cc1a","cell_type":"code","source":"import os\nimport logging\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:20.182013Z","iopub.execute_input":"2025-08-27T07:10:20.182335Z","iopub.status.idle":"2025-08-27T07:10:20.193223Z","shell.execute_reply.started":"2025-08-27T07:10:20.182308Z","shell.execute_reply":"2025-08-27T07:10:20.187878Z"}},"outputs":[],"execution_count":2},{"id":"f5e56fa9-b62c-4a43-9c78-a681d7c07809","cell_type":"code","source":"import tensorflow as tf\nprint(tf.config.list_logical_devices())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"791b1c6c-f114-409f-a500-7a0edae02210","cell_type":"code","source":"import tensorflow as tf\n\nprint(\"TPU devices:\", tf.config.experimental.list_logical_devices('TPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"735c66a7-3e2d-4151-962d-adada0a0839b","cell_type":"code","source":"try:\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.TPUStrategy(resolver)\n    print(\"✅ TPU initialized\")\nexcept Exception as e:\n    print(\"⚠️ No TPU, fallback:\", e)\n    strategy = tf.distribute.get_strategy()\n\nprint(\"Số replicas:\", strategy.num_replicas_in_sync)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:23.759248Z","iopub.execute_input":"2025-08-27T07:10:23.759539Z","iopub.status.idle":"2025-08-27T07:10:32.245814Z","shell.execute_reply.started":"2025-08-27T07:10:23.759514Z","shell.execute_reply":"2025-08-27T07:10:32.241511Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1756278628.035224      10 service.cc:148] XLA service 0x584c40c61330 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1756278628.035280      10 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1756278628.035285      10 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1756278628.035288      10 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1756278628.035292      10 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1756278628.035297      10 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1756278628.035300      10 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1756278628.035303      10 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1756278628.035305      10 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"✅ TPU initialized\nSố replicas: 8\n","output_type":"stream"}],"execution_count":3},{"id":"550991d6","cell_type":"markdown","source":"## Load Processed Data","metadata":{"id":"550991d6"}},{"id":"0ca3fd5c","cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sentiment-classification-nmq/train.csv')\nvalid_df = pd.read_csv('/kaggle/input/sentiment-classification-nmq/valid.csv')\ntest_df = pd.read_csv('/kaggle/input/sentiment-classification-nmq/test.csv')","metadata":{"id":"0ca3fd5c","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:32.247779Z","iopub.execute_input":"2025-08-27T07:10:32.248004Z","iopub.status.idle":"2025-08-27T07:10:38.308894Z","shell.execute_reply.started":"2025-08-27T07:10:32.247969Z","shell.execute_reply":"2025-08-27T07:10:38.304411Z"}},"outputs":[],"execution_count":4},{"id":"e6f5ef8b-0403-48a7-82cb-1fb5c251ee3f","cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"72d9b645","cell_type":"markdown","source":"## Load Pretrained Word2Vec","metadata":{"id":"72d9b645"}},{"id":"3dd68680","cell_type":"code","source":"word2vec_file_path = '/kaggle/input/pho-word2vec/word2vec_vi_words_300dims.txt'","metadata":{"id":"3dd68680","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:38.311054Z","iopub.execute_input":"2025-08-27T07:10:38.311581Z","iopub.status.idle":"2025-08-27T07:10:38.322326Z","shell.execute_reply.started":"2025-08-27T07:10:38.311555Z","shell.execute_reply":"2025-08-27T07:10:38.316216Z"}},"outputs":[],"execution_count":5},{"id":"e4dc867f","cell_type":"code","source":"class Vocab:\n    def __init__(self, w2v_file_path: str):\n        self.word_index = {}\n        self.embedding_matrix = []\n        self.embedding_dim = None\n        self.load_word2vec(w2v_file_path)\n        self.embedding_matrix = np.array(self.embedding_matrix, dtype='float32')\n        self.unk_id = self.word_index['<unk>']\n        self.pad_id = self.word_index['<pad>']\n\n    def load_word2vec(self, file_path: str):\n        with open(file_path, 'r', encoding='utf-8') as f:\n            first_line = f.readline().strip().split()\n            if (len(first_line) == 2 and first_line[0].isdigit()):\n                self.embedding_dim = int(first_line[1])\n            else:\n                f.seek(0)\n            for line in f:\n                values = line.strip().split()\n                if len(values) < self.embedding_dim + 1:\n                    continue\n                word = '_'.join(values[: - self.embedding_dim]).lower()\n                if word in self.word_index:\n                    continue\n                try:\n                    vector = np.asarray(values[- self.embedding_dim :], dtype='float32')\n                except ValueError:\n                    print(f'Error line: {line.strip()}')\n                    continue\n                self.word_index[word] = len(self.word_index)\n                self.embedding_matrix.append(vector)\n\n        self.word_index['<unk>'] = len(self.word_index)\n        self.embedding_matrix.append(np.random.uniform(-0.05, 0.05, self.embedding_dim))\n\n        self.word_index['<pad>'] = len(self.word_index)\n        self.embedding_matrix.append(np.zeros(self.embedding_dim))\n\n        for word in ['happy', 'love', 'sad', 'angry', 'surprise', 'thinking', 'neutral']:\n            if f'<{word}>' not in self.word_index:\n                dot_id = self.word_index.get('.')\n                word_id = self.word_index.get(word)\n                if dot_id is None or word_id is None:\n                    continue\n                dot_vector = self.embedding_matrix[dot_id]\n                word_vector = self.embedding_matrix[word_id]\n                vector = (dot_vector + word_vector) / 2\n\n                self.word_index[f'<{word}>'] = len(self.word_index)\n                self.embedding_matrix.append(vector)\n\n    def get_index(self, word: str) -> int:\n        return self.word_index.get(word, self.unk_id)","metadata":{"id":"e4dc867f","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:38.324387Z","iopub.execute_input":"2025-08-27T07:10:38.324612Z","iopub.status.idle":"2025-08-27T07:10:38.340448Z","shell.execute_reply.started":"2025-08-27T07:10:38.324589Z","shell.execute_reply":"2025-08-27T07:10:38.336639Z"}},"outputs":[],"execution_count":6},{"id":"bc22d813","cell_type":"code","source":"vocab = Vocab(word2vec_file_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc22d813","outputId":"ba4f5001-c6e4-41ca-e39b-91c339df7720","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:10:38.343401Z","iopub.execute_input":"2025-08-27T07:10:38.343611Z","iopub.status.idle":"2025-08-27T07:13:21.536789Z","shell.execute_reply.started":"2025-08-27T07:10:38.343590Z","shell.execute_reply":"2025-08-27T07:13:21.530886Z"}},"outputs":[],"execution_count":7},{"id":"94e5c85e","cell_type":"markdown","source":"## Tokenize and Pad Sequences","metadata":{"id":"94e5c85e"}},{"id":"a779cd17","cell_type":"code","source":"lengths = train_df['sent'].apply(lambda x: len(x.split()))\nplt.hist(lengths, bins=50, color='green')\nplt.xlabel('Lengths')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"a779cd17","outputId":"15cb863d-edcc-4d2b-8e45-accf5d04d267","trusted":true},"outputs":[],"execution_count":null},{"id":"ba7fa28d","cell_type":"code","source":"MAX_LENGTH_SENT = 512","metadata":{"id":"ba7fa28d","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.541046Z","iopub.execute_input":"2025-08-27T07:13:21.541274Z","iopub.status.idle":"2025-08-27T07:13:21.549607Z","shell.execute_reply.started":"2025-08-27T07:13:21.541246Z","shell.execute_reply":"2025-08-27T07:13:21.545400Z"}},"outputs":[],"execution_count":8},{"id":"555a1ec3","cell_type":"code","source":"class Tokenizer:\n    def __init__(self, vocab: Vocab, max_len: int):\n        self.vocab = vocab\n        self.max_len = max_len\n\n    def encode(self, text):\n        tokens = text.split()\n        ids = [self.vocab.get_index(token) for token in tokens]\n        return ids[:self.max_len]\n\n    def pad_sequence(self, seq: list[int]) -> list[int]:\n        if len(seq) < self.max_len:\n            seq = seq + [self.vocab.pad_id] * (self.max_len - len(seq))\n        return seq[:self.max_len]\n\n    def encode_batch(self, texts: list[str]) -> np.ndarray:\n        return np.array([self.pad_sequence(self.encode(text)) for text in texts])","metadata":{"id":"555a1ec3","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.551726Z","iopub.execute_input":"2025-08-27T07:13:21.551945Z","iopub.status.idle":"2025-08-27T07:13:21.565858Z","shell.execute_reply.started":"2025-08-27T07:13:21.551923Z","shell.execute_reply":"2025-08-27T07:13:21.560142Z"}},"outputs":[],"execution_count":9},{"id":"96135273","cell_type":"code","source":"tokenizer = Tokenizer(vocab, MAX_LENGTH_SENT)","metadata":{"id":"96135273","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.567556Z","iopub.execute_input":"2025-08-27T07:13:21.567788Z","iopub.status.idle":"2025-08-27T07:13:21.576431Z","shell.execute_reply.started":"2025-08-27T07:13:21.567766Z","shell.execute_reply":"2025-08-27T07:13:21.571606Z"}},"outputs":[],"execution_count":10},{"id":"406dd4fa","cell_type":"markdown","source":"## Label Encoder","metadata":{"id":"406dd4fa"}},{"id":"6be126d2","cell_type":"code","source":"class LabelEncoder:\n    def __init__(self, labels: list['str']):\n        self.label2id = {}\n        self.id2label = {}\n        for label in labels:\n            self.label2id[label] = len(self.label2id)\n            self.id2label[len(self.id2label)] = label\n\n    def encode_batch(self, labels: list[str]):\n        return [self.label2id[label] for label in labels]\n\n    def decode_batch(self, ids: list[int]):\n        return [self.id2label[id] for id in ids]","metadata":{"id":"6be126d2","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.578061Z","iopub.execute_input":"2025-08-27T07:13:21.578442Z","iopub.status.idle":"2025-08-27T07:13:21.588501Z","shell.execute_reply.started":"2025-08-27T07:13:21.578421Z","shell.execute_reply":"2025-08-27T07:13:21.583919Z"}},"outputs":[],"execution_count":11},{"id":"26a3e54a","cell_type":"code","source":"label_encoder = LabelEncoder(['POS', 'NEG', 'NEU'])","metadata":{"id":"26a3e54a","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.590164Z","iopub.execute_input":"2025-08-27T07:13:21.590392Z","iopub.status.idle":"2025-08-27T07:13:21.599496Z","shell.execute_reply.started":"2025-08-27T07:13:21.590371Z","shell.execute_reply":"2025-08-27T07:13:21.594330Z"}},"outputs":[],"execution_count":12},{"id":"192456e1","cell_type":"markdown","source":"## Create Dataset","metadata":{"id":"192456e1"}},{"id":"f0297e3c","cell_type":"code","source":"class Dataset:\n    def __init__(self, df: pd.DataFrame, tokenizer: Tokenizer, label_encoder: LabelEncoder):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.label_encoder = label_encoder\n\n    def build(self, batch_size=32, shuffle=True):\n        X = self.tokenizer.encode_batch(self.df['sent'].tolist())\n        y = self.label_encoder.encode_batch(self.df['sentiment'].tolist())\n\n        X = np.array(X, dtype=np.int32)\n        y = np.array(y, dtype=np.int32)\n\n        dataset = tf.data.Dataset.from_tensor_slices((X, y))\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=len(X))\n        dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n        return dataset","metadata":{"id":"f0297e3c","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.601426Z","iopub.execute_input":"2025-08-27T07:13:21.601775Z","iopub.status.idle":"2025-08-27T07:13:21.613906Z","shell.execute_reply.started":"2025-08-27T07:13:21.601754Z","shell.execute_reply":"2025-08-27T07:13:21.608764Z"}},"outputs":[],"execution_count":13},{"id":"e9cf8c2e","cell_type":"code","source":"train_dataset = Dataset(\n    df=train_df,\n    tokenizer=tokenizer,\n    label_encoder=label_encoder\n).build(batch_size=64)\n\nvalid_dataset = Dataset(\n    df=valid_df,\n    tokenizer=tokenizer,\n    label_encoder=label_encoder\n).build(batch_size=64, shuffle=False)\n\ntest_dataset = Dataset(\n    df=test_df,\n    tokenizer=tokenizer,\n    label_encoder=label_encoder\n).build(batch_size=64, shuffle=False)","metadata":{"id":"e9cf8c2e","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:21.615015Z","iopub.execute_input":"2025-08-27T07:13:21.615202Z","iopub.status.idle":"2025-08-27T07:13:42.267770Z","shell.execute_reply.started":"2025-08-27T07:13:21.615183Z","shell.execute_reply":"2025-08-27T07:13:42.262226Z"}},"outputs":[],"execution_count":14},{"id":"bcf6c396","cell_type":"markdown","source":"## Define Model","metadata":{"id":"bcf6c396"}},{"id":"b3b5ee71","cell_type":"code","source":"class InceptionRes1D(Layer):\n    def __init__(\n        self, \n        branch_filters: list[int], \n        kernel_sizes: list[int], \n        output_dim: int\n    ):\n        super().__init__()\n        assert len(branch_filters) == len(kernel_sizes), 'filters and kernel_sizes must have same length'\n        self.output_dim = output_dim\n        self.input_norm = LayerNormalization()\n        self.branches = []\n        for f, k in zip(branch_filters, kernel_sizes):\n            self.branches.append(Conv1D(filters=f, kernel_size=k, padding='same', activation=None, kernel_initializer=HeNormal()))\n        self.conv1x1 = Conv1D(filters=output_dim, kernel_size=1, padding='same', activation=None, kernel_initializer=HeNormal())\n\n        self.res_conv = None\n        self.out_norm = LayerNormalization(axis=-1)\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n        if input_dim != self.output_dim:\n            self.res_conv = Conv1D(self.output_dim, 1, padding='same', activation=None)\n        super().build(input_shape)\n\n    def call(self, x, training=False):\n        x = self.input_norm(x)\n        branch_outputs = []\n        for conv in self.branches:\n            out = conv(x)\n            out = tf.nn.gelu(out)\n            branch_outputs.append(out)\n\n        x_concat = tf.concat(branch_outputs, axis=-1)\n\n        out = self.conv1x1(x_concat)\n        \n        residual = self.res_conv(x) if self.res_conv else x\n            \n        return tf.nn.gelu(self.out_norm(residual + out))\n\nclass CNNEncoder(Layer):\n    def __init__(\n        self,\n        inception_configs=[\n            {'branch_filters': [128, 64, 32], 'kernel_sizes': [2, 3, 5]},\n            {'branch_filters': [256, 128, 64], 'kernel_sizes': [2, 3, 5]},\n            {'branch_filters': [512, 256, 128], 'kernel_sizes': [2, 3, 5]},\n        ],\n        pooling_configs=[\n            {'type': 'max', 'size': 5, 'strides': 3, 'padding': 'same'},\n            {'type': 'max', 'size': 3, 'strides': 2, 'padding': 'same'},\n            {'type': 'global_max'},\n        ],\n        res_output_dims=[300, 300, 300],\n        fc_configs=[\n            {'dim': 512, 'activation': 'gelu', 'dropout': 0.3},\n            {'dim': 256, 'activation': 'gelu', 'dropout': 0.3}\n        ]\n    ):\n        super(CNNEncoder, self).__init__()\n        self.layers = []\n        for inception_config, pooling_config, output_dim in zip(inception_configs, pooling_configs, res_output_dims):\n            self.layers.append(InceptionRes1D(\n                branch_filters=inception_config['branch_filters'],\n                kernel_sizes=inception_config['kernel_sizes'],\n                output_dim = output_dim\n            ))\n            if pooling_config['type'] == 'max':\n                self.layers.append(MaxPooling1D(\n                    pool_size=pooling_config['size'],\n                    strides=pooling_config['strides'],\n                    padding=pooling_config['padding']\n                ))\n            elif pooling_config['type'] == 'global_max':\n                self.layers.append(GlobalMaxPooling1D())\n            elif pooling_config['type'] == 'average':\n                self.layers.append(AveragePooling1D(\n                    pool_size=pooling_config['size'],\n                    strides=pooling_config['strides']\n                ))\n            elif pooling_config['type'] == 'global_average':\n                self.layers.append(GlobalAveragePooling1D())\n        self.fcs = []\n        for config in fc_configs:\n            self.fcs.append(Dense(config['dim'], activation=config['activation'], kernel_initializer=HeNormal()))\n            if 'dropout' in config:\n                self.fcs.append(Dropout(config['dropout']))\n        self.fcs = Sequential(self.fcs)\n\n    def call(self, x, training=False):\n        for layer in self.layers:\n            if isinstance(layer, InceptionRes1D):\n                x = layer(x, training=training)\n            else:\n                x = layer(x)\n        pattern = self.fcs(x)    \n        return pattern","metadata":{"id":"b3b5ee71","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:42.269610Z","iopub.execute_input":"2025-08-27T07:13:42.270112Z","iopub.status.idle":"2025-08-27T07:13:42.292003Z","shell.execute_reply.started":"2025-08-27T07:13:42.270085Z","shell.execute_reply":"2025-08-27T07:13:42.287417Z"}},"outputs":[],"execution_count":15},{"id":"4cfbaf7c-80d8-4d79-bdfc-5238743974f5","cell_type":"code","source":"class RNNEncoder(Layer):\n    def __init__(\n        self,\n        lstm_hidden_dim,\n        fc_configs\n    ):\n        super().__init__()\n        self.bilstm = Bidirectional(LSTM(lstm_hidden_dim, return_sequences=True, dropout=0.3))\n        self.lstm_post_norm = LayerNormalization()\n        self.attn_fc = Dense(1, activation=None)\n        self.fcs = []\n        for config in fc_configs:\n            self.fcs.append(Dense(config['dim'], activation=config['activation']))\n            if 'dropout' in config:\n                self.fcs.append(Dropout(config['dropout']))\n        self.fcs = Sequential(self.fcs)\n    def call(self, x, mask):\n        hiddens = self.bilstm(x, mask=mask)\n        hiddens = self.lstm_post_norm(hiddens)\n        \n        scores = self.attn_fc(hiddens)\n        scores = tf.squeeze(scores, axis=-1)\n        weights = tf.nn.softmax(scores, axis=-1)\n        context = tf.reduce_sum(hiddens * tf.expand_dims(weights, -1), axis=-2)\n        \n        context = self.fcs(context)\n        return hiddens, context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:42.294212Z","iopub.execute_input":"2025-08-27T07:13:42.295408Z","iopub.status.idle":"2025-08-27T07:13:42.312408Z","shell.execute_reply.started":"2025-08-27T07:13:42.295381Z","shell.execute_reply":"2025-08-27T07:13:42.307865Z"}},"outputs":[],"execution_count":16},{"id":"bc28adb7","cell_type":"code","source":"class Attention(Layer):\n    def __init__(self, attention_dim):\n        super().__init__()\n        self.dense = Dense(attention_dim, activation='tanh')\n        self.v = Dense(1, activation=None)\n\n    def call(self, hiddens, pattern, mask):\n        \"\"\"\n        Args:\n            hiddens: [B, S, 2H]\n            pattern: [B, P]\n        Returns:\n            context: [B, 2H]\n            attn_weights: [B, S, 1]\n        \"\"\"\n        \n        S = tf.shape(hiddens)[1]\n        \n        # [B, P] -> [B, 1, P] -> [B, S, P]\n        exp_pattern = tf.tile(tf.expand_dims(pattern, 1), [1, S, 1])\n\n        # [B, S, 2H] cat [B, S, P] -> [B, S, 2H + P]\n        score_input = tf.concat([hiddens, exp_pattern], axis=-1)\n\n        # [B, S, 2H + P] -> [B, S, A] -> [B, S, 1]\n        score = self.v(self.dense(score_input))\n\n        if mask is not None:\n            mask = tf.cast(mask, tf.float32)\n            mask = tf.expand_dims(mask, -1)\n            score += (1.0 - mask) * -1e9\n        \n        attn_weights = tf.nn.softmax(score, axis=1)\n\n        # [B, S, 1] * [B, S, 2H] -> [B, S, 2H] -> [B, 2H]\n        context = tf.reduce_sum(attn_weights * hiddens, axis=1)\n\n        return context","metadata":{"id":"bc28adb7","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:42.314486Z","iopub.execute_input":"2025-08-27T07:13:42.314888Z","iopub.status.idle":"2025-08-27T07:13:42.329894Z","shell.execute_reply.started":"2025-08-27T07:13:42.314864Z","shell.execute_reply":"2025-08-27T07:13:42.325465Z"}},"outputs":[],"execution_count":17},{"id":"4f1d3d33","cell_type":"code","source":"class HybridModel(Model):\n    def __init__(\n        self,\n        vocab,\n        cnn_inception_configs,\n        cnn_pooling_configs,\n        cnn_output_dims,\n        cnn_fc_configs,\n        lstm_hidden_dim,\n        rnn_fc_configs,\n        attention_dim,\n        fc_out_configs,\n        output_dim,\n        trainable_embeddings=False,\n    ):\n        super().__init__()\n        self.vocab = vocab\n\n        self.embedding = Embedding(\n            input_dim=len(vocab.word_index),\n            output_dim=vocab.embedding_dim,\n            weights=[vocab.embedding_matrix],\n            trainable=trainable_embeddings,\n            mask_zero=False\n        )\n\n        self.embedding_adapter = Dense(vocab.embedding_dim, activation='gelu')\n        \n        self.cnn_encoder = CNNEncoder(\n            inception_configs=cnn_inception_configs,\n            pooling_configs=cnn_pooling_configs,\n            res_output_dims=cnn_output_dims,\n            fc_configs=cnn_fc_configs\n        )\n        \n        self.rnn_encoder = RNNEncoder(\n            lstm_hidden_dim=lstm_hidden_dim,\n            fc_configs=rnn_fc_configs\n        )\n        \n        self.attention = Attention(attention_dim=attention_dim)\n\n        self.rnn_context_norm = LayerNormalization()\n        self.cnn_context_norm = LayerNormalization()\n        self.pattern_norm = LayerNormalization()\n\n        self.fcs = []\n        for config in fc_out_configs:\n            self.fcs.append(Dense(config['dim'], activation=config['activation']))\n            if 'dropout' in config:\n                self.fcs.append(Dropout(config['dropout']))\n        self.fcs.append(Dense(output_dim, activation='softmax'))\n        self.fcs = Sequential(self.fcs)\n\n    def call(self, x, training=False):\n        \"\"\"\n        Args:\n            x: [B, S]\n        Returns:\n            out: [B, 3]\n        \"\"\"\n        # [B, S] -> [B, S, D]\n        embedded_x = self.embedding(x)\n        embedded_x = self.embedding_adapter(embedded_x)\n\n        mask = tf.not_equal(x, self.vocab.pad_id)\n        \n        # [B, S, 2H]\n        rnn_hiddens, rnn_context = self.rnn_encoder(embedded_x, mask)\n        rnn_context = self.rnn_context_norm(rnn_context)\n\n        # [B, S, D] -> [B, P]\n        pattern = self.cnn_encoder(rnn_hiddens, training=training)\n        pattern = self.pattern_norm(pattern)\n\n        # context: [B, 2H]\n        cnn_context = self.attention(rnn_hiddens, pattern, mask)\n        cnn_context = self.cnn_context_norm(cnn_context)\n\n        out = tf.concat([cnn_context, rnn_context], axis=-1)\n\n        out = self.fcs(out)\n\n        return out","metadata":{"id":"4f1d3d33","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:42.332071Z","iopub.execute_input":"2025-08-27T07:13:42.332292Z","iopub.status.idle":"2025-08-27T07:13:42.348006Z","shell.execute_reply.started":"2025-08-27T07:13:42.332270Z","shell.execute_reply":"2025-08-27T07:13:42.343043Z"}},"outputs":[],"execution_count":18},{"id":"5ddf66d5","cell_type":"markdown","source":"## Train","metadata":{"id":"5ddf66d5"}},{"id":"fe441b8c","cell_type":"code","source":"with strategy.scope():\n    model = HybridModel(\n        vocab=vocab,\n        lstm_hidden_dim=256,\n        rnn_fc_configs=[\n            {'dim': 512, 'activation': 'gelu', 'dropout': 0.25},\n            {'dim': 256, 'activation': 'gelu', 'dropout': 0.25},\n        ],\n        cnn_inception_configs=[\n            {'branch_filters': [128, 64, 32], 'kernel_sizes': [2, 3, 5]},\n            {'branch_filters': [256, 128, 64], 'kernel_sizes': [2, 3, 5]},\n        ],\n        cnn_pooling_configs=[\n            {'type': 'max', 'size': 3, 'strides': 1, 'padding': 'same'},\n            {'type': 'global_average'},\n        ],\n        cnn_output_dims=[512, 512],\n        cnn_fc_configs=[\n            {'dim': 512, 'activation': 'relu', 'dropout': 0.25},\n            {'dim': 256, 'activation': 'relu', 'dropout': 0.25}\n        ],\n        attention_dim=512,\n        fc_out_configs=[\n            {'dim': 512, 'activation': 'gelu', 'dropout': 0.2},\n            {'dim': 256, 'activation': 'gelu', 'dropout': 0.2},\n            {'dim': 128, 'activation': 'gelu', 'dropout': 0.2},\n        ],\n        output_dim=3,\n    )\n\n    dummy_input = tf.zeros((1, 512), dtype=tf.int32)\n    _ = model(dummy_input)\n    \n    model.compile(\n        optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=5e-3),\n        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n        # metrics=['accuracy']\n    )","metadata":{"id":"fe441b8c","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:13:42.349687Z","iopub.execute_input":"2025-08-27T07:13:42.349908Z","iopub.status.idle":"2025-08-27T07:14:16.249838Z","shell.execute_reply.started":"2025-08-27T07:13:42.349886Z","shell.execute_reply":"2025-08-27T07:14:16.245470Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1756278822.429003      10 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":19},{"id":"75521b8e-055e-4746-a3ae-e311326f7ddb","cell_type":"code","source":"class WeightedF1Checkpoint(tf.keras.callbacks.Callback):\n    def __init__(self, val_dataset, save_path='best_model.weights.h5'):\n        super().__init__()\n        self.val_dataset = val_dataset\n        self.save_path = save_path\n        self.best_f1_weighted = 0.0\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_pred_prob = self.model.predict(self.val_dataset)\n        y_pred = np.argmax(y_pred_prob, axis=1)\n        \n        y_true = np.concatenate([y for x, y in self.val_dataset], axis=0)\n\n        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n\n        print(f\"val_weighted_f1 = {f1_weighted:.4f}\")\n        \n        if f1_weighted > self.best_f1_weighted:\n            self.best_f1_weighted = f1_weighted\n            self.model.save_weights(self.save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:14:16.251785Z","iopub.execute_input":"2025-08-27T07:14:16.252026Z","iopub.status.idle":"2025-08-27T07:14:16.263418Z","shell.execute_reply.started":"2025-08-27T07:14:16.252003Z","shell.execute_reply":"2025-08-27T07:14:16.259146Z"}},"outputs":[],"execution_count":20},{"id":"a229c6be","cell_type":"code","source":"# early_stop = EarlyStopping(\n#     monitor='val_loss',\n#     patience=5,\n#     restore_best_weights=False\n# )\n\nf1_callback = WeightedF1Checkpoint(\n    valid_dataset, \n    save_path='best_model.weights.h5'\n)\n\nclass_weight = {\n    label_encoder.label2id['POS']: 1.0,\n    label_encoder.label2id['NEG']: 1.0 / 0.7,\n    label_encoder.label2id['NEU']: 1.0 / 0.55,\n}","metadata":{"id":"a229c6be","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:15:03.566415Z","iopub.execute_input":"2025-08-27T07:15:03.566741Z","iopub.status.idle":"2025-08-27T07:15:03.578334Z","shell.execute_reply.started":"2025-08-27T07:15:03.566715Z","shell.execute_reply":"2025-08-27T07:15:03.572492Z"}},"outputs":[],"execution_count":22},{"id":"962a2c6c","cell_type":"code","source":"with strategy.scope():\n    history = model.fit(\n        train_dataset,\n        validation_data=valid_dataset,\n        epochs=30,\n        callbacks=[\n            f1_callback, \n            # early_stop\n        ],\n        class_weight=class_weight\n    )","metadata":{"id":"962a2c6c","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T07:15:06.664632Z","iopub.execute_input":"2025-08-27T07:15:06.664951Z","iopub.status.idle":"2025-08-27T13:35:50.998653Z","shell.execute_reply.started":"2025-08-27T07:15:06.664924Z","shell.execute_reply":"2025-08-27T13:35:50.992219Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756278918.606209      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:3088870120923251187\nI0000 00:00:1756278921.014146     942 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(16586193888508352171), session_name()\nI0000 00:00:1756278939.783540     942 tpu_compile_op_common.cc:245] Compilation of 16586193888508352171 with session name  took 18.76934551s and succeeded\nI0000 00:00:1756278939.851894     942 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(16586193888508352171), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_3088870120923251187\", property.function_library_fingerprint = 14440420843803009582, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,512,;8,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756278939.851937     942 tpu_compilation_cache_interface.cc:542] After adding entry for key 16586193888508352171 with session_name  cache is 1 entries (90937230 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3625/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.9248","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756279655.939227     928 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(1823147710482391409), session_name()\nI0000 00:00:1756279675.715718     928 tpu_compile_op_common.cc:245] Compilation of 1823147710482391409 with session name  took 19.776443137s and succeeded\nI0000 00:00:1756279675.799355     928 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(1823147710482391409), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_3088870120923251187\", property.function_library_fingerprint = 14440420843803009582, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"7,512,;7,;7,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756279675.799413     928 tpu_compilation_cache_interface.cc:542] After adding entry for key 1823147710482391409 with session_name  cache is 2 entries (183064038 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.9248","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756279679.459241      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:8890144241869602698\nI0000 00:00:1756279679.954033     909 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(16989962942665468449), session_name()\nI0000 00:00:1756279682.979983     909 tpu_compile_op_common.cc:245] Compilation of 16989962942665468449 with session name  took 3.025905765s and succeeded\nI0000 00:00:1756279682.989588     909 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(16989962942665468449), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_8890144241869602698\", property.function_library_fingerprint = 15896164004160230510, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,512,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756279682.989620     909 tpu_compilation_cache_interface.cc:542] After adding entry for key 16989962942665468449 with session_name  cache is 3 entries (196955594 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1756279693.795921     876 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(1466543090134734288), session_name()\nI0000 00:00:1756279695.867078     876 tpu_compile_op_common.cc:245] Compilation of 1466543090134734288 with session name  took 2.071121117s and succeeded\nI0000 00:00:1756279695.874714     876 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(1466543090134734288), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_8890144241869602698\", property.function_library_fingerprint = 15896164004160230510, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,512,;2,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756279695.874740     876 tpu_compilation_cache_interface.cc:542] After adding entry for key 1466543090134734288 with session_name  cache is 4 entries (209178292 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1756279697.776498      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:2201331674470811106\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756279697.853561      10 meta_optimizer.cc:966] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node hybrid_model_1/attention_1/dense_6_1/BiasAdd/ReadVariableOp.\nI0000 00:00:1756279698.026109     886 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(11554019587114233803), session_name()\nI0000 00:00:1756279700.672283     886 tpu_compile_op_common.cc:245] Compilation of 11554019587114233803 with session name  took 2.646130987s and succeeded\nI0000 00:00:1756279700.678356     886 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(11554019587114233803), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_2201331674470811106\", property.function_library_fingerprint = 17124798683456662897, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756279700.678384     886 tpu_compilation_cache_interface.cc:542] After adding entry for key 11554019587114233803 with session_name  cache is 5 entries (220330950 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m292/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756279717.833607      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:18172037700898505644\nI0000 00:00:1756279718.190131     880 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(6556355573928910235), session_name()\nI0000 00:00:1756279720.094234     880 tpu_compile_op_common.cc:245] Compilation of 6556355573928910235 with session name  took 1.904049096s and succeeded\nI0000 00:00:1756279720.102684     880 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(6556355573928910235), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_18172037700898505644\", property.function_library_fingerprint = 3478284551076888438, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,512,;2,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756279720.102714     880 tpu_compilation_cache_interface.cc:542] After adding entry for key 6556355573928910235 with session_name  cache is 6 entries (231935796 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step\nval_weighted_f1 = 0.8171\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 217ms/step - loss: 0.9248 - val_loss: 0.5054\nEpoch 2/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8302\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 208ms/step - loss: 0.6621 - val_loss: 0.4717\nEpoch 3/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8468\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 208ms/step - loss: 0.6073 - val_loss: 0.4110\nEpoch 4/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8576\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 209ms/step - loss: 0.5637 - val_loss: 0.3918\nEpoch 5/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8547\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 205ms/step - loss: 0.5439 - val_loss: 0.4066\nEpoch 6/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8541\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 206ms/step - loss: 0.5043 - val_loss: 0.4137\nEpoch 7/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8563\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 206ms/step - loss: 0.4855 - val_loss: 0.3990\nEpoch 8/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8559\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 206ms/step - loss: 0.4671 - val_loss: 0.3917\nEpoch 9/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8665\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 209ms/step - loss: 0.4423 - val_loss: 0.3754\nEpoch 10/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step\nval_weighted_f1 = 0.8396\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 209ms/step - loss: 0.4236 - val_loss: 0.4507\nEpoch 11/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8802\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m769s\u001b[0m 212ms/step - loss: 0.4132 - val_loss: 0.3376\nEpoch 12/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step\nval_weighted_f1 = 0.8707\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 209ms/step - loss: 0.3761 - val_loss: 0.3680\nEpoch 13/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step\nval_weighted_f1 = 0.8750\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 210ms/step - loss: 0.3753 - val_loss: 0.3555\nEpoch 14/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8806\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 211ms/step - loss: 0.3525 - val_loss: 0.3445\nEpoch 15/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step\nval_weighted_f1 = 0.8682\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 209ms/step - loss: 0.3476 - val_loss: 0.3744\nEpoch 16/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8771\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 209ms/step - loss: 0.3428 - val_loss: 0.3610\nEpoch 17/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step\nval_weighted_f1 = 0.8843\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 212ms/step - loss: 0.3313 - val_loss: 0.3359\nEpoch 18/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step\nval_weighted_f1 = 0.8809\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 209ms/step - loss: 0.3191 - val_loss: 0.3482\nEpoch 19/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step\nval_weighted_f1 = 0.8828\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 209ms/step - loss: 0.3032 - val_loss: 0.3575\nEpoch 20/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step\nval_weighted_f1 = 0.8753\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 209ms/step - loss: 0.2950 - val_loss: 0.3795\nEpoch 21/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step\nval_weighted_f1 = 0.8872\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 212ms/step - loss: 0.2676 - val_loss: 0.3531\nEpoch 22/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step\nval_weighted_f1 = 0.8702\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 210ms/step - loss: 0.2690 - val_loss: 0.4173\nEpoch 23/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8841\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 209ms/step - loss: 0.2432 - val_loss: 0.3697\nEpoch 24/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step\nval_weighted_f1 = 0.8813\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 209ms/step - loss: 0.2422 - val_loss: 0.3673\nEpoch 25/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8858\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 209ms/step - loss: 0.2481 - val_loss: 0.3760\nEpoch 26/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 73ms/step\nval_weighted_f1 = 0.8890\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 213ms/step - loss: 0.2224 - val_loss: 0.3727\nEpoch 27/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8833\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 209ms/step - loss: 0.2216 - val_loss: 0.3854\nEpoch 28/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8808\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 209ms/step - loss: 0.2154 - val_loss: 0.4050\nEpoch 29/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step\nval_weighted_f1 = 0.8802\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 209ms/step - loss: 0.2168 - val_loss: 0.3985\nEpoch 30/30\n\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step\nval_weighted_f1 = 0.8826\n\u001b[1m3626/3626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 209ms/step - loss: 0.2043 - val_loss: 0.3946\n","output_type":"stream"}],"execution_count":23},{"id":"d1e443c2","cell_type":"markdown","source":"## Test","metadata":{"id":"d1e443c2"}},{"id":"9ccdcb22-8e43-4816-bcd8-ab36e66b8c65","cell_type":"code","source":"model.load_weights('/kaggle/working/best_model.weights.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:38:24.424392Z","iopub.execute_input":"2025-08-27T13:38:24.424780Z","iopub.status.idle":"2025-08-27T13:38:31.372426Z","shell.execute_reply.started":"2025-08-27T13:38:24.424748Z","shell.execute_reply":"2025-08-27T13:38:31.366851Z"}},"outputs":[],"execution_count":28},{"id":"8d08d551-f35f-4a37-82c2-305be45a742e","cell_type":"code","source":"y_pred_prob = model.predict(test_dataset)\ny_pred = np.argmax(y_pred_prob, axis=1)\n\ny_true = np.concatenate([y for x, y in test_dataset], axis=0)\n\nacc = accuracy_score(y_true, y_pred)\nprint(f'Accuracy: {acc:.4f}\\n')\n\n# F1 Score\nprint(\"F1 Scores:\")\nprint(f\"\\tMacro:    {f1_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"\\tMicro:    {f1_score(y_true, y_pred, average='micro'):.4f}\")\nprint(f\"\\tWeighted: {f1_score(y_true, y_pred, average='weighted'):.4f}\\n\")\n\n# Precision\nprint(\"Precision Scores:\")\nprint(f\"\\tMacro:    {precision_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"\\tMicro:    {precision_score(y_true, y_pred, average='micro'):.4f}\")\nprint(f\"\\tWeighted: {precision_score(y_true, y_pred, average='weighted'):.4f}\\n\")\n\n# Recall\nprint(\"Recall Scores:\")\nprint(f\"\\tMacro:    {recall_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"\\tMicro:    {recall_score(y_true, y_pred, average='micro'):.4f}\")\nprint(f\"\\tWeighted: {recall_score(y_true, y_pred, average='weighted'):.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T13:38:34.128380Z","iopub.execute_input":"2025-08-27T13:38:34.128728Z","iopub.status.idle":"2025-08-27T13:38:54.901476Z","shell.execute_reply.started":"2025-08-27T13:38:34.128699Z","shell.execute_reply":"2025-08-27T13:38:54.894910Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step\nAccuracy: 0.8801\n\nF1 Scores:\n\tMacro:    0.7385\n\tMicro:    0.8801\n\tWeighted: 0.8858\n\nPrecision Scores:\n\tMacro:    0.7176\n\tMicro:    0.8801\n\tWeighted: 0.8943\n\nRecall Scores:\n\tMacro:    0.7690\n\tMicro:    0.8801\n\tWeighted: 0.8801\n\n","output_type":"stream"}],"execution_count":29}]}